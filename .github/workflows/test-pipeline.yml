name: ATHintel Test Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  schedule:
    # Run comprehensive tests daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'
  POSTGRES_VERSION: '15'
  REDIS_VERSION: '7'
  
  # Test environment variables
  DATABASE_URL: postgresql://test_user:test_password@localhost:5432/test_athintel
  REDIS_URL: redis://localhost:6379/15
  
  # Security test configuration
  VAULT_URL: http://localhost:8200
  VAULT_TOKEN: test-vault-token
  CREDENTIAL_MASTER_KEY: test-master-key-for-ci
  
  # Performance test thresholds
  MAX_RESPONSE_TIME_MS: 2000
  MIN_THROUGHPUT_RPS: 50
  MAX_MEMORY_MB: 512

jobs:
  # === SECURITY TESTS ===
  security-tests:
    name: ğŸ” Security & Vulnerability Tests
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: test_athintel
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
      
      vault:
        image: hashicorp/vault:latest
        env:
          VAULT_DEV_ROOT_TOKEN_ID: test-vault-token
          VAULT_DEV_LISTEN_ADDRESS: 0.0.0.0:8200
        options: >-
          --cap-add=IPC_LOCK
        ports:
          - 8200:8200
    
    steps:
      - name: ğŸ” Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for security scanning
      
      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev,enterprise]"
          pip install safety bandit semgrep
      
      - name: ğŸ›¡ï¸ Run credential manager security tests
        run: |
          python -m pytest tests/security/test_secure_credential_manager.py \
            --verbose --tb=short \
            --cov=src/config/secure_credential_manager \
            --cov-report=xml:coverage-security-credentials.xml
        env:
          PYTHONPATH: .
      
      - name: ğŸ”’ Run error handler security tests
        run: |
          python -m pytest tests/security/test_secure_error_handler.py \
            --verbose --tb=short \
            --cov=src/utils/secure_error_handler \
            --cov-report=xml:coverage-security-errors.xml
        env:
          PYTHONPATH: .
      
      - name: ğŸ›¡ï¸ Run input validation security tests
        run: |
          python -m pytest tests/security/test_input_validator.py \
            --verbose --tb=short \
            --cov=src/security/input_validator \
            --cov-report=xml:coverage-security-validation.xml
        env:
          PYTHONPATH: .
      
      - name: ğŸ” Run dependency vulnerability scan
        run: |
          safety check --json --output safety-report.json
          bandit -r src/ -f json -o bandit-report.json
        continue-on-error: true
      
      - name: ğŸ•µï¸ Run SAST with Semgrep
        run: |
          semgrep --config=auto src/ --json --output=semgrep-report.json
        continue-on-error: true
      
      - name: ğŸ“Š Upload security test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: security-test-reports
          path: |
            coverage-security-*.xml
            safety-report.json
            bandit-report.json
            semgrep-report.json
          retention-days: 30

  # === UNIT TESTS ===
  unit-tests:
    name: ğŸ§ª Unit Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    strategy:
      matrix:
        python-version: ['3.11', '3.12']
        test-group: ['core', 'services', 'utilities', 'analytics']
    
    steps:
      - name: ğŸ” Checkout code
        uses: actions/checkout@v4
      
      - name: ğŸ Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
      
      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"
      
      - name: ğŸ§ª Run unit tests for ${{ matrix.test-group }}
        run: |
          python -m pytest tests/unit/ \
            -k "${{ matrix.test-group }}" \
            --verbose --tb=short \
            --cov=src \
            --cov-report=xml:coverage-unit-${{ matrix.test-group }}.xml \
            --cov-report=html:htmlcov-unit-${{ matrix.test-group }} \
            --junit-xml=junit-unit-${{ matrix.test-group }}.xml \
            --durations=10
        env:
          PYTHONPATH: .
      
      - name: ğŸ“Š Upload unit test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: unit-test-results-${{ matrix.python-version }}-${{ matrix.test-group }}
          path: |
            coverage-unit-${{ matrix.test-group }}.xml
            htmlcov-unit-${{ matrix.test-group }}/
            junit-unit-${{ matrix.test-group }}.xml
          retention-days: 30

  # === FUNCTIONAL TESTS ===
  functional-tests:
    name: âš™ï¸ Functional Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: test_athintel
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
      - name: ğŸ” Checkout code
        uses: actions/checkout@v4
      
      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev,enterprise]"
      
      - name: ğŸ—ï¸ Set up test database
        run: |
          python scripts/setup_test_database.py
        env:
          PYTHONPATH: .
      
      - name: âš™ï¸ Run energy assessment functional tests
        run: |
          python -m pytest tests/functional/test_energy_assessment_pipeline.py \
            --verbose --tb=short \
            --cov=src/core/services/energy_assessment \
            --cov-report=xml:coverage-functional-energy.xml \
            --junit-xml=junit-functional-energy.xml
        env:
          PYTHONPATH: .
      
      - name: ğŸ’° Run investment recommendation functional tests
        run: |
          python -m pytest tests/functional/test_investment_recommendations.py \
            --verbose --tb=short \
            --cov=src/core/services/investment_analysis \
            --cov-report=xml:coverage-functional-investment.xml \
            --junit-xml=junit-functional-investment.xml
        env:
          PYTHONPATH: .
      
      - name: ğŸ“Š Upload functional test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: functional-test-results
          path: |
            coverage-functional-*.xml
            junit-functional-*.xml
          retention-days: 30

  # === INTEGRATION TESTS ===
  integration-tests:
    name: ğŸ”— Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: test_athintel
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
      - name: ğŸ” Checkout code
        uses: actions/checkout@v4
      
      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: ğŸš€ Set up Node.js for API testing
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: ğŸ“¦ Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev,enterprise]"
      
      - name: ğŸ“¦ Install Node.js dependencies
        run: |
          npm install newman @apidevtools/swagger-parser
      
      - name: ğŸ—ï¸ Set up test environment
        run: |
          python scripts/setup_integration_test_environment.py
        env:
          PYTHONPATH: .
      
      - name: ğŸŒ Run API integration tests
        run: |
          python -m pytest tests/integration/test_api_integration.py \
            --verbose --tb=short \
            --cov=src/api \
            --cov-report=xml:coverage-integration-api.xml \
            --junit-xml=junit-integration-api.xml
        env:
          PYTHONPATH: .
      
      - name: ğŸ—„ï¸ Run database integration tests
        run: |
          python -m pytest tests/integration/test_database_integration.py \
            --verbose --tb=short \
            --cov=src/infrastructure/database \
            --cov-report=xml:coverage-integration-db.xml \
            --junit-xml=junit-integration-db.xml
        env:
          PYTHONPATH: .
      
      - name: ğŸ”— Run external service integration tests
        run: |
          python -m pytest tests/integration/test_external_services.py \
            --verbose --tb=short \
            --cov=src/integrations \
            --cov-report=xml:coverage-integration-external.xml \
            --junit-xml=junit-integration-external.xml
        env:
          PYTHONPATH: .
          # Mock external services in CI
          MOCK_EXTERNAL_SERVICES: "true"
      
      - name: ğŸ“Š Upload integration test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: integration-test-results
          path: |
            coverage-integration-*.xml
            junit-integration-*.xml
          retention-days: 30

  # === PERFORMANCE TESTS ===
  performance-tests:
    name: ğŸš€ Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: test_athintel
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
          --shm-size=256m
        ports:
          - 5432:5432
      
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
      - name: ğŸ” Checkout code
        uses: actions/checkout@v4
      
      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev,enterprise]"
          pip install locust
      
      - name: ğŸ—ï¸ Set up performance test environment
        run: |
          python scripts/setup_performance_test_environment.py
        env:
          PYTHONPATH: .
      
      - name: âš¡ Run performance benchmarks
        run: |
          python -m pytest tests/performance/test_performance_benchmarks.py \
            --verbose --tb=short \
            -m "not slow" \
            --junit-xml=junit-performance.xml
        env:
          PYTHONPATH: .
      
      - name: ğŸ”„ Run resilience pattern tests
        run: |
          python -m pytest tests/resilience/test_circuit_breaker_patterns.py \
            --verbose --tb=short \
            --junit-xml=junit-resilience.xml
        env:
          PYTHONPATH: .
      
      - name: ğŸ“Š Generate performance report
        run: |
          python scripts/generate_performance_report.py \
            --output performance-report.html \
            --threshold-response-time ${{ env.MAX_RESPONSE_TIME_MS }} \
            --threshold-throughput ${{ env.MIN_THROUGHPUT_RPS }} \
            --threshold-memory ${{ env.MAX_MEMORY_MB }}
        if: always()
      
      - name: ğŸ“Š Upload performance test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: performance-test-results
          path: |
            junit-performance.xml
            junit-resilience.xml
            performance-report.html
          retention-days: 30

  # === E2E TESTS ===
  e2e-tests:
    name: ğŸ­ End-to-End Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    if: github.event_name != 'pull_request' || contains(github.event.pull_request.labels.*.name, 'run-e2e')
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: test_athintel
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
      - name: ğŸ” Checkout code
        uses: actions/checkout@v4
      
      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: ğŸš€ Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: ğŸ“¦ Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev,enterprise]"
          pip install playwright
      
      - name: ğŸ“¦ Install Node.js dependencies
        run: |
          npm install
      
      - name: ğŸ­ Install Playwright browsers
        run: |
          playwright install chromium firefox webkit
      
      - name: ğŸ—ï¸ Set up E2E test environment
        run: |
          python scripts/setup_e2e_test_environment.py
        env:
          PYTHONPATH: .
      
      - name: ğŸš€ Start application server
        run: |
          python -m uvicorn src.main:app --host 0.0.0.0 --port 8000 &
          sleep 10  # Wait for server to start
        env:
          PYTHONPATH: .
          DATABASE_URL: ${{ env.DATABASE_URL }}
          REDIS_URL: ${{ env.REDIS_URL }}
      
      - name: ğŸ­ Run Playwright E2E tests
        run: |
          python -m pytest tests/e2e/ \
            --verbose --tb=short \
            --browser chromium \
            --junit-xml=junit-e2e.xml
        env:
          PYTHONPATH: .
          BASE_URL: http://localhost:8000
      
      - name: ğŸ“Š Upload E2E test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: e2e-test-results
          path: |
            junit-e2e.xml
            test-results/
            playwright-report/
          retention-days: 30

  # === TEST COVERAGE CONSOLIDATION ===
  coverage-report:
    name: ğŸ“Š Coverage Report
    runs-on: ubuntu-latest
    needs: [security-tests, unit-tests, functional-tests, integration-tests]
    if: always()
    
    steps:
      - name: ğŸ” Checkout code
        uses: actions/checkout@v4
      
      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: ğŸ“¦ Install coverage tools
        run: |
          pip install coverage[toml] codecov
      
      - name: ğŸ“¥ Download all test artifacts
        uses: actions/download-artifact@v3
        with:
          path: test-artifacts
      
      - name: ğŸ”„ Combine coverage reports
        run: |
          coverage combine test-artifacts/**/*coverage*.xml
          coverage report --show-missing
          coverage xml -o coverage-combined.xml
          coverage html -d htmlcov-combined
        continue-on-error: true
      
      - name: ğŸ“Š Upload combined coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: coverage-combined.xml
          name: athintel-coverage
          fail_ci_if_error: false
      
      - name: ğŸ“Š Upload coverage report
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: coverage-report-combined
          path: |
            coverage-combined.xml
            htmlcov-combined/
          retention-days: 90
      
      - name: ğŸ“Š Coverage summary comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            try {
              const coverage = fs.readFileSync('coverage-combined.xml', 'utf8');
              // Parse coverage percentage and create comment
              const match = coverage.match(/line-rate="([0-9.]+)"/);
              if (match) {
                const percentage = (parseFloat(match[1]) * 100).toFixed(1);
                await github.rest.issues.createComment({
                  issue_number: context.issue.number,
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  body: `## ğŸ“Š Test Coverage Report\n\n**Total Coverage: ${percentage}%**\n\nDetailed coverage report available in artifacts.`
                });
              }
            } catch (error) {
              console.log('Could not create coverage comment:', error);
            }

  # === QUALITY GATES ===
  quality-gate:
    name: ğŸ† Quality Gate
    runs-on: ubuntu-latest
    needs: [security-tests, unit-tests, functional-tests, integration-tests, performance-tests, coverage-report]
    if: always()
    
    steps:
      - name: ğŸ” Checkout code
        uses: actions/checkout@v4
      
      - name: ğŸ“¥ Download test results
        uses: actions/download-artifact@v3
        with:
          path: all-test-results
      
      - name: ğŸ” Analyze test results
        run: |
          python scripts/analyze_test_results.py \
            --results-dir all-test-results \
            --output quality-gate-report.json
        continue-on-error: true
      
      - name: ğŸ† Quality gate decision
        id: quality-gate
        run: |
          python scripts/quality_gate_decision.py \
            --report quality-gate-report.json \
            --min-coverage 85 \
            --max-security-issues 0 \
            --max-failed-tests 0 \
            --max-performance-degradation 20
          echo "quality-gate-passed=$?" >> $GITHUB_OUTPUT
      
      - name: ğŸ“Š Upload quality gate report
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: quality-gate-report
          path: quality-gate-report.json
          retention-days: 90
      
      - name: âŒ Fail pipeline if quality gate fails
        if: steps.quality-gate.outputs.quality-gate-passed != '0'
        run: |
          echo "Quality gate failed! Check the quality gate report for details."
          exit 1
      
      - name: âœ… Quality gate passed
        if: steps.quality-gate.outputs.quality-gate-passed == '0'
        run: |
          echo "ğŸ‰ Quality gate passed! All tests meet the required standards."

  # === NIGHTLY COMPREHENSIVE TESTS ===
  nightly-comprehensive:
    name: ğŸŒ™ Nightly Comprehensive Tests
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    timeout-minutes: 120
    
    strategy:
      matrix:
        test-suite: ['load-test', 'stress-test', 'endurance-test', 'chaos-test']
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: test_athintel
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
      - name: ğŸ” Checkout code
        uses: actions/checkout@v4
      
      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev,enterprise]"
          pip install locust pytest-benchmark pytest-timeout
      
      - name: ğŸ—ï¸ Set up comprehensive test environment
        run: |
          python scripts/setup_comprehensive_test_environment.py \
            --test-suite ${{ matrix.test-suite }}
        env:
          PYTHONPATH: .
      
      - name: ğŸš€ Run ${{ matrix.test-suite }}
        run: |
          python scripts/run_comprehensive_test.py \
            --test-suite ${{ matrix.test-suite }} \
            --duration 3600 \
            --output comprehensive-${{ matrix.test-suite }}-report.json
        env:
          PYTHONPATH: .
        timeout-minutes: 90
      
      - name: ğŸ“Š Upload comprehensive test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: comprehensive-test-results-${{ matrix.test-suite }}
          path: comprehensive-${{ matrix.test-suite }}-report.json
          retention-days: 30
      
      - name: ğŸ“§ Notify on failure
        if: failure()
        uses: actions/github-script@v6
        with:
          script: |
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `ğŸš¨ Nightly ${{ matrix.test-suite }} Failed`,
              body: `The nightly ${{ matrix.test-suite }} failed on ${new Date().toISOString()}.\n\nPlease check the workflow run: ${context.payload.repository.html_url}/actions/runs/${context.runId}`,
              labels: ['bug', 'nightly-test-failure', 'priority-high']
            });

# === CLEANUP ===
  cleanup:
    name: ğŸ§¹ Cleanup
    runs-on: ubuntu-latest
    needs: [quality-gate, nightly-comprehensive]
    if: always()
    
    steps:
      - name: ğŸ§¹ Clean up test artifacts older than 30 days
        uses: actions/github-script@v6
        with:
          script: |
            const thirtyDaysAgo = new Date();
            thirtyDaysAgo.setDate(thirtyDaysAgo.getDate() - 30);
            
            const artifacts = await github.rest.actions.listArtifactsForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              per_page: 100
            });
            
            for (const artifact of artifacts.data.artifacts) {
              const createdAt = new Date(artifact.created_at);
              if (createdAt < thirtyDaysAgo) {
                try {
                  await github.rest.actions.deleteArtifact({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    artifact_id: artifact.id
                  });
                  console.log(`Deleted artifact: ${artifact.name}`);
                } catch (error) {
                  console.log(`Failed to delete artifact ${artifact.name}: ${error}`);
                }
              }
            }